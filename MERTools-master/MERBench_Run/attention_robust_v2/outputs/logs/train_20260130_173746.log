====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', fusion_temperature=1.0, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_weight=0.01, l2=5e-05, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v2', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='/root/autodl-tmp/MERTools-master/MERBench/attention_robust_v2/outputs/results-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|                                                                                               | 0/3373 [00:00<?, ?it/s] 34%|███████████████████████████▊                                                     | 1158/3373 [00:00<00:00, 11569.50it/s] 69%|███████████████████████████████████████████████████████▌                         | 2315/3373 [00:00<00:00, 11111.82it/s]100%|█████████████████████████████████████████████████████████████████████████████████| 3373/3373 [00:00<00:00, 11302.60it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|                                                                                               | 0/3373 [00:00<?, ?it/s] 26%|█████████████████████▎                                                             | 865/3373 [00:00<00:00, 8609.61it/s] 56%|█████████████████████████████████████████████▋                                    | 1879/3373 [00:00<00:00, 9498.15it/s] 84%|████████████████████████████████████████████████████████████████████▊             | 2829/3373 [00:00<00:00, 9424.60it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 3373/3373 [00:00<00:00, 9313.88it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|                                                                                               | 0/3373 [00:00<?, ?it/s] 47%|██████████████████████████████████████▍                                          | 1600/3373 [00:00<00:00, 15931.23it/s] 95%|████████████████████████████████████████████████████████████████████████████▋    | 3194/3373 [00:00<00:00, 13008.93it/s]100%|█████████████████████████████████████████████████████████████████████████████████| 3373/3373 [00:00<00:00, 13587.11it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|                                                                                                | 0/411 [00:00<?, ?it/s]100%|████████████████████████████████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 8351.18it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|                                                                                                | 0/411 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 13204.39it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|                                                                                                | 0/411 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 15350.21it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|                                                                                                | 0/412 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 412/412 [00:00<00:00, 16223.72it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|                                                                                                | 0/412 [00:00<?, ?it/s]100%|████████████████████████████████████████████████████████████████████████████████████| 412/412 [00:00<00:00, 9000.46it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|                                                                                                | 0/412 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 412/412 [00:00<00:00, 15433.87it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|                                                                                                | 0/834 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 834/834 [00:00<00:00, 14020.91it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|                                                                                                | 0/834 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 834/834 [00:00<00:00, 10530.49it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|                                                                                                | 0/834 [00:00<?, ?it/s]100%|███████████████████████████████████████████████████████████████████████████████████| 834/834 [00:00<00:00, 12773.18it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.1437; eval:0.2884; lr:0.000500
epoch:2; metric:emoval; train:0.2760; eval:0.4306; lr:0.000500
epoch:3; metric:emoval; train:0.3909; eval:0.5010; lr:0.000500
epoch:4; metric:emoval; train:0.4830; eval:0.5177; lr:0.000500
epoch:5; metric:emoval; train:0.5405; eval:0.4801; lr:0.000500
epoch:6; metric:emoval; train:0.5860; eval:0.5174; lr:0.000500
epoch:7; metric:emoval; train:0.6168; eval:0.5409; lr:0.000500
epoch:8; metric:emoval; train:0.6533; eval:0.5568; lr:0.000500
epoch:9; metric:emoval; train:0.6479; eval:0.5511; lr:0.000500
epoch:10; metric:emoval; train:0.7098; eval:0.5543; lr:0.000500
epoch:11; metric:emoval; train:0.7222; eval:0.5643; lr:0.000500
epoch:12; metric:emoval; train:0.7353; eval:0.5422; lr:0.000500
epoch:13; metric:emoval; train:0.7411; eval:0.5000; lr:0.000500
epoch:14; metric:emoval; train:0.7506; eval:0.5033; lr:0.000500
epoch:15; metric:emoval; train:0.7551; eval:0.5444; lr:0.000500
epoch:16; metric:emoval; train:0.7832; eval:0.5354; lr:0.000500
epoch:17; metric:emoval; train:0.7963; eval:0.5713; lr:0.000500
epoch:18; metric:emoval; train:0.7792; eval:0.5330; lr:0.000500
epoch:19; metric:emoval; train:0.7997; eval:0.5484; lr:0.000500
epoch:20; metric:emoval; train:0.8172; eval:0.5513; lr:0.000500
epoch:21; metric:emoval; train:0.8248; eval:0.5168; lr:0.000500
epoch:22; metric:emoval; train:0.8194; eval:0.5389; lr:0.000500
epoch:23; metric:emoval; train:0.8040; eval:0.5228; lr:0.000500
epoch:24; metric:emoval; train:0.8354; eval:0.5277; lr:0.000500
epoch:25; metric:emoval; train:0.8328; eval:0.5301; lr:0.000500
epoch:26; metric:emoval; train:0.8358; eval:0.5415; lr:0.000500
epoch:27; metric:emoval; train:0.8254; eval:0.5308; lr:0.000500
epoch:28; metric:emoval; train:0.8438; eval:0.5202; lr:0.000250
epoch:29; metric:emoval; train:0.8667; eval:0.5380; lr:0.000250
epoch:30; metric:emoval; train:0.8726; eval:0.5330; lr:0.000250
epoch:31; metric:emoval; train:0.8823; eval:0.5706; lr:0.000250
epoch:32; metric:emoval; train:0.8879; eval:0.5606; lr:0.000250
epoch:33; metric:emoval; train:0.8870; eval:0.5521; lr:0.000250
epoch:34; metric:emoval; train:0.8902; eval:0.5490; lr:0.000250
epoch:35; metric:emoval; train:0.8954; eval:0.5446; lr:0.000250
epoch:36; metric:emoval; train:0.8929; eval:0.5569; lr:0.000250
epoch:37; metric:emoval; train:0.8952; eval:0.5505; lr:0.000250
epoch:38; metric:emoval; train:0.8912; eval:0.5631; lr:0.000250
epoch:39; metric:emoval; train:0.8979; eval:0.5626; lr:0.000125
epoch:40; metric:emoval; train:0.9078; eval:0.5549; lr:0.000125
epoch:41; metric:emoval; train:0.9157; eval:0.5313; lr:0.000125
epoch:42; metric:emoval; train:0.9148; eval:0.5638; lr:0.000125
epoch:43; metric:emoval; train:0.9153; eval:0.5559; lr:0.000125
epoch:44; metric:emoval; train:0.9226; eval:0.5648; lr:0.000125
epoch:45; metric:emoval; train:0.9173; eval:0.5524; lr:0.000125
epoch:46; metric:emoval; train:0.9166; eval:0.5323; lr:0.000125
epoch:47; metric:emoval; train:0.9127; eval:0.5544; lr:0.000125
Early stopping at epoch 47, best epoch: 17
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 16, duration: 131.30806970596313 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.1763; eval:0.1902; lr:0.000500
epoch:2; metric:emoval; train:0.2138; eval:0.4269; lr:0.000500
epoch:3; metric:emoval; train:0.3842; eval:0.4298; lr:0.000500
epoch:4; metric:emoval; train:0.4541; eval:0.5490; lr:0.000500
epoch:5; metric:emoval; train:0.5293; eval:0.4459; lr:0.000500
epoch:6; metric:emoval; train:0.5875; eval:0.5546; lr:0.000500
epoch:7; metric:emoval; train:0.6073; eval:0.5530; lr:0.000500
epoch:8; metric:emoval; train:0.6306; eval:0.4086; lr:0.000500
epoch:9; metric:emoval; train:0.6667; eval:0.5469; lr:0.000500
epoch:10; metric:emoval; train:0.6838; eval:0.5752; lr:0.000500
epoch:11; metric:emoval; train:0.7103; eval:0.5522; lr:0.000500
epoch:12; metric:emoval; train:0.7093; eval:0.5685; lr:0.000500
epoch:13; metric:emoval; train:0.7225; eval:0.5579; lr:0.000500
epoch:14; metric:emoval; train:0.7151; eval:0.5465; lr:0.000500
epoch:15; metric:emoval; train:0.7476; eval:0.5453; lr:0.000500
epoch:16; metric:emoval; train:0.7573; eval:0.5854; lr:0.000500
epoch:17; metric:emoval; train:0.7764; eval:0.5419; lr:0.000500
epoch:18; metric:emoval; train:0.7573; eval:0.5331; lr:0.000500
epoch:19; metric:emoval; train:0.7922; eval:0.5636; lr:0.000500
epoch:20; metric:emoval; train:0.7761; eval:0.5715; lr:0.000500
epoch:21; metric:emoval; train:0.7751; eval:0.5640; lr:0.000500
epoch:22; metric:emoval; train:0.7982; eval:0.5334; lr:0.000500
epoch:23; metric:emoval; train:0.8065; eval:0.5944; lr:0.000500
epoch:24; metric:emoval; train:0.8104; eval:0.5555; lr:0.000500
epoch:25; metric:emoval; train:0.8162; eval:0.5622; lr:0.000500
epoch:26; metric:emoval; train:0.7994; eval:0.6144; lr:0.000500
epoch:27; metric:emoval; train:0.8006; eval:0.5656; lr:0.000500
epoch:28; metric:emoval; train:0.8070; eval:0.5841; lr:0.000500
epoch:29; metric:emoval; train:0.8254; eval:0.5560; lr:0.000500
epoch:30; metric:emoval; train:0.8381; eval:0.5611; lr:0.000500
epoch:31; metric:emoval; train:0.8282; eval:0.5817; lr:0.000500
epoch:32; metric:emoval; train:0.8446; eval:0.5812; lr:0.000500
epoch:33; metric:emoval; train:0.8429; eval:0.5541; lr:0.000500
epoch:34; metric:emoval; train:0.8409; eval:0.5516; lr:0.000500
epoch:35; metric:emoval; train:0.8422; eval:0.5469; lr:0.000500
epoch:36; metric:emoval; train:0.8280; eval:0.5641; lr:0.000500
epoch:37; metric:emoval; train:0.8535; eval:0.5903; lr:0.000250
epoch:38; metric:emoval; train:0.8709; eval:0.5819; lr:0.000250
epoch:39; metric:emoval; train:0.8754; eval:0.5827; lr:0.000250
epoch:40; metric:emoval; train:0.8812; eval:0.5725; lr:0.000250
epoch:41; metric:emoval; train:0.8827; eval:0.5899; lr:0.000250
epoch:42; metric:emoval; train:0.8843; eval:0.5680; lr:0.000250
epoch:43; metric:emoval; train:0.8846; eval:0.5821; lr:0.000250
epoch:44; metric:emoval; train:0.8858; eval:0.5592; lr:0.000250
epoch:45; metric:emoval; train:0.8914; eval:0.5859; lr:0.000250
epoch:46; metric:emoval; train:0.8907; eval:0.5637; lr:0.000250
epoch:47; metric:emoval; train:0.8919; eval:0.5846; lr:0.000250
epoch:48; metric:emoval; train:0.8842; eval:0.5981; lr:0.000125
epoch:49; metric:emoval; train:0.8991; eval:0.5954; lr:0.000125
epoch:50; metric:emoval; train:0.9091; eval:0.6013; lr:0.000125
epoch:51; metric:emoval; train:0.9080; eval:0.5828; lr:0.000125
epoch:52; metric:emoval; train:0.9108; eval:0.5801; lr:0.000125
epoch:53; metric:emoval; train:0.9083; eval:0.5844; lr:0.000125
epoch:54; metric:emoval; train:0.9077; eval:0.5658; lr:0.000125
epoch:55; metric:emoval; train:0.9085; eval:0.5881; lr:0.000125
epoch:56; metric:emoval; train:0.9132; eval:0.5722; lr:0.000125
Early stopping at epoch 56, best epoch: 26
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 25, duration: 151.13600730895996 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.1453; eval:0.3148; lr:0.000500
epoch:2; metric:emoval; train:0.2487; eval:0.3670; lr:0.000500
epoch:3; metric:emoval; train:0.4146; eval:0.4618; lr:0.000500
epoch:4; metric:emoval; train:0.4980; eval:0.4966; lr:0.000500
epoch:5; metric:emoval; train:0.5466; eval:0.5658; lr:0.000500
epoch:6; metric:emoval; train:0.6154; eval:0.6040; lr:0.000500
epoch:7; metric:emoval; train:0.6407; eval:0.5612; lr:0.000500
epoch:8; metric:emoval; train:0.6309; eval:0.5289; lr:0.000500
epoch:9; metric:emoval; train:0.6641; eval:0.5768; lr:0.000500
epoch:10; metric:emoval; train:0.6965; eval:0.5209; lr:0.000500
epoch:11; metric:emoval; train:0.7167; eval:0.5632; lr:0.000500
epoch:12; metric:emoval; train:0.7331; eval:0.5869; lr:0.000500
epoch:13; metric:emoval; train:0.7426; eval:0.6019; lr:0.000500
epoch:14; metric:emoval; train:0.7637; eval:0.5824; lr:0.000500
epoch:15; metric:emoval; train:0.7621; eval:0.5913; lr:0.000500
epoch:16; metric:emoval; train:0.7787; eval:0.5692; lr:0.000500
epoch:17; metric:emoval; train:0.7680; eval:0.5817; lr:0.000250
epoch:18; metric:emoval; train:0.8119; eval:0.5790; lr:0.000250
epoch:19; metric:emoval; train:0.8313; eval:0.5836; lr:0.000250
epoch:20; metric:emoval; train:0.8333; eval:0.5721; lr:0.000250
epoch:21; metric:emoval; train:0.8305; eval:0.5620; lr:0.000250
epoch:22; metric:emoval; train:0.8354; eval:0.5861; lr:0.000250
epoch:23; metric:emoval; train:0.8509; eval:0.5729; lr:0.000250
epoch:24; metric:emoval; train:0.8422; eval:0.5883; lr:0.000250
epoch:25; metric:emoval; train:0.8446; eval:0.5787; lr:0.000250
epoch:26; metric:emoval; train:0.8504; eval:0.5894; lr:0.000250
epoch:27; metric:emoval; train:0.8501; eval:0.5966; lr:0.000250
epoch:28; metric:emoval; train:0.8570; eval:0.5716; lr:0.000125
epoch:29; metric:emoval; train:0.8780; eval:0.5895; lr:0.000125
epoch:30; metric:emoval; train:0.8819; eval:0.5935; lr:0.000125
epoch:31; metric:emoval; train:0.8805; eval:0.6003; lr:0.000125
epoch:32; metric:emoval; train:0.8813; eval:0.5970; lr:0.000125
epoch:33; metric:emoval; train:0.8815; eval:0.5793; lr:0.000125
epoch:34; metric:emoval; train:0.8906; eval:0.5763; lr:0.000125
epoch:35; metric:emoval; train:0.8841; eval:0.5868; lr:0.000125
epoch:36; metric:emoval; train:0.8769; eval:0.5906; lr:0.000125
Early stopping at epoch 36, best epoch: 6
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 5, duration: 101.06559824943542 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.2083; eval:0.2190; lr:0.000500
epoch:2; metric:emoval; train:0.2817; eval:0.4110; lr:0.000500
epoch:3; metric:emoval; train:0.4066; eval:0.4693; lr:0.000500
epoch:4; metric:emoval; train:0.4765; eval:0.4949; lr:0.000500
epoch:5; metric:emoval; train:0.5545; eval:0.5393; lr:0.000500
epoch:6; metric:emoval; train:0.5783; eval:0.5332; lr:0.000500
epoch:7; metric:emoval; train:0.6346; eval:0.5388; lr:0.000500
epoch:8; metric:emoval; train:0.6514; eval:0.5391; lr:0.000500
epoch:9; metric:emoval; train:0.6769; eval:0.5620; lr:0.000500
epoch:10; metric:emoval; train:0.7133; eval:0.5399; lr:0.000500
epoch:11; metric:emoval; train:0.6906; eval:0.5595; lr:0.000500
epoch:12; metric:emoval; train:0.7333; eval:0.5543; lr:0.000500
epoch:13; metric:emoval; train:0.7375; eval:0.5698; lr:0.000500
epoch:14; metric:emoval; train:0.7394; eval:0.5252; lr:0.000500
epoch:15; metric:emoval; train:0.7582; eval:0.5753; lr:0.000500
epoch:16; metric:emoval; train:0.7632; eval:0.5516; lr:0.000500
epoch:17; metric:emoval; train:0.7683; eval:0.4822; lr:0.000500
epoch:18; metric:emoval; train:0.7655; eval:0.5596; lr:0.000500
epoch:19; metric:emoval; train:0.7952; eval:0.5588; lr:0.000500
epoch:20; metric:emoval; train:0.8030; eval:0.5367; lr:0.000500
epoch:21; metric:emoval; train:0.8110; eval:0.5431; lr:0.000500
epoch:22; metric:emoval; train:0.8071; eval:0.5708; lr:0.000500
epoch:23; metric:emoval; train:0.8187; eval:0.5516; lr:0.000500
epoch:24; metric:emoval; train:0.8163; eval:0.5111; lr:0.000500
epoch:25; metric:emoval; train:0.8157; eval:0.5747; lr:0.000500
epoch:26; metric:emoval; train:0.8279; eval:0.5474; lr:0.000250
epoch:27; metric:emoval; train:0.8561; eval:0.5291; lr:0.000250
epoch:28; metric:emoval; train:0.8655; eval:0.5318; lr:0.000250
epoch:29; metric:emoval; train:0.8578; eval:0.5549; lr:0.000250
epoch:30; metric:emoval; train:0.8684; eval:0.5227; lr:0.000250
epoch:31; metric:emoval; train:0.8588; eval:0.5517; lr:0.000250
epoch:32; metric:emoval; train:0.8648; eval:0.5546; lr:0.000250
epoch:33; metric:emoval; train:0.8710; eval:0.5509; lr:0.000250
epoch:34; metric:emoval; train:0.8839; eval:0.5507; lr:0.000250
epoch:35; metric:emoval; train:0.8713; eval:0.5550; lr:0.000250
epoch:36; metric:emoval; train:0.8707; eval:0.5534; lr:0.000250
epoch:37; metric:emoval; train:0.8635; eval:0.5566; lr:0.000125
epoch:38; metric:emoval; train:0.8858; eval:0.5718; lr:0.000125
epoch:39; metric:emoval; train:0.8942; eval:0.5637; lr:0.000125
epoch:40; metric:emoval; train:0.8973; eval:0.5623; lr:0.000125
epoch:41; metric:emoval; train:0.8997; eval:0.5578; lr:0.000125
epoch:42; metric:emoval; train:0.9005; eval:0.5440; lr:0.000125
epoch:43; metric:emoval; train:0.9021; eval:0.5523; lr:0.000125
epoch:44; metric:emoval; train:0.8986; eval:0.5689; lr:0.000125
epoch:45; metric:emoval; train:0.9050; eval:0.5490; lr:0.000125
Early stopping at epoch 45, best epoch: 15
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 14, duration: 120.0590615272522 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.1526; eval:0.2717; lr:0.000500
epoch:2; metric:emoval; train:0.2568; eval:0.3562; lr:0.000500
epoch:3; metric:emoval; train:0.4055; eval:0.4924; lr:0.000500
epoch:4; metric:emoval; train:0.4651; eval:0.4770; lr:0.000500
epoch:5; metric:emoval; train:0.5321; eval:0.4810; lr:0.000500
epoch:6; metric:emoval; train:0.5705; eval:0.5798; lr:0.000500
epoch:7; metric:emoval; train:0.6230; eval:0.5669; lr:0.000500
epoch:8; metric:emoval; train:0.6360; eval:0.5584; lr:0.000500
epoch:9; metric:emoval; train:0.6849; eval:0.5700; lr:0.000500
epoch:10; metric:emoval; train:0.6935; eval:0.5340; lr:0.000500
epoch:11; metric:emoval; train:0.6989; eval:0.5665; lr:0.000500
epoch:12; metric:emoval; train:0.7107; eval:0.5580; lr:0.000500
epoch:13; metric:emoval; train:0.7519; eval:0.5895; lr:0.000500
epoch:14; metric:emoval; train:0.7704; eval:0.5453; lr:0.000500
epoch:15; metric:emoval; train:0.7517; eval:0.5390; lr:0.000500
epoch:16; metric:emoval; train:0.7725; eval:0.5405; lr:0.000500
epoch:17; metric:emoval; train:0.7957; eval:0.5841; lr:0.000500
epoch:18; metric:emoval; train:0.7893; eval:0.5223; lr:0.000500
epoch:19; metric:emoval; train:0.8001; eval:0.5460; lr:0.000500
epoch:20; metric:emoval; train:0.8127; eval:0.5892; lr:0.000500
epoch:21; metric:emoval; train:0.8003; eval:0.5830; lr:0.000500
epoch:22; metric:emoval; train:0.8102; eval:0.5749; lr:0.000500
epoch:23; metric:emoval; train:0.8091; eval:0.5492; lr:0.000500
epoch:24; metric:emoval; train:0.8305; eval:0.5633; lr:0.000250
epoch:25; metric:emoval; train:0.8355; eval:0.5906; lr:0.000250
epoch:26; metric:emoval; train:0.8673; eval:0.5872; lr:0.000250
epoch:27; metric:emoval; train:0.8692; eval:0.5884; lr:0.000250
epoch:28; metric:emoval; train:0.8648; eval:0.5749; lr:0.000250
epoch:29; metric:emoval; train:0.8676; eval:0.5779; lr:0.000250
epoch:30; metric:emoval; train:0.8738; eval:0.5951; lr:0.000250
epoch:31; metric:emoval; train:0.8781; eval:0.5764; lr:0.000250
epoch:32; metric:emoval; train:0.8829; eval:0.5774; lr:0.000250
epoch:33; metric:emoval; train:0.8789; eval:0.5724; lr:0.000250
epoch:34; metric:emoval; train:0.8907; eval:0.5724; lr:0.000250
epoch:35; metric:emoval; train:0.8760; eval:0.5695; lr:0.000250
epoch:36; metric:emoval; train:0.8745; eval:0.5854; lr:0.000250
epoch:37; metric:emoval; train:0.8853; eval:0.5883; lr:0.000250
epoch:38; metric:emoval; train:0.8898; eval:0.5971; lr:0.000250
epoch:39; metric:emoval; train:0.8886; eval:0.5813; lr:0.000250
epoch:40; metric:emoval; train:0.8892; eval:0.5401; lr:0.000250
epoch:41; metric:emoval; train:0.8818; eval:0.5596; lr:0.000250
epoch:42; metric:emoval; train:0.8942; eval:0.5653; lr:0.000250
epoch:43; metric:emoval; train:0.8909; eval:0.6004; lr:0.000250
epoch:44; metric:emoval; train:0.8914; eval:0.5616; lr:0.000250
epoch:45; metric:emoval; train:0.8890; eval:0.5807; lr:0.000250
epoch:46; metric:emoval; train:0.9014; eval:0.5903; lr:0.000250
epoch:47; metric:emoval; train:0.8939; eval:0.5628; lr:0.000250
epoch:48; metric:emoval; train:0.8788; eval:0.5218; lr:0.000250
epoch:49; metric:emoval; train:0.8899; eval:0.5820; lr:0.000250
epoch:50; metric:emoval; train:0.8966; eval:0.5724; lr:0.000250
epoch:51; metric:emoval; train:0.8907; eval:0.5578; lr:0.000250
epoch:52; metric:emoval; train:0.8993; eval:0.5678; lr:0.000250
epoch:53; metric:emoval; train:0.8923; eval:0.5657; lr:0.000250
epoch:54; metric:emoval; train:0.8909; eval:0.5727; lr:0.000125
epoch:55; metric:emoval; train:0.9078; eval:0.5675; lr:0.000125
epoch:56; metric:emoval; train:0.9171; eval:0.5687; lr:0.000125
epoch:57; metric:emoval; train:0.9202; eval:0.5654; lr:0.000125
epoch:58; metric:emoval; train:0.9193; eval:0.5553; lr:0.000125
epoch:59; metric:emoval; train:0.9180; eval:0.5629; lr:0.000125
epoch:60; metric:emoval; train:0.9265; eval:0.5727; lr:0.000125
epoch:61; metric:emoval; train:0.9227; eval:0.5642; lr:0.000125
epoch:62; metric:emoval; train:0.9261; eval:0.5680; lr:0.000125
epoch:63; metric:emoval; train:0.9198; eval:0.5716; lr:0.000125
epoch:64; metric:emoval; train:0.9182; eval:0.5597; lr:0.000125
epoch:65; metric:emoval; train:0.9188; eval:0.5678; lr:0.000063
epoch:66; metric:emoval; train:0.9251; eval:0.5631; lr:0.000063
epoch:67; metric:emoval; train:0.9296; eval:0.5762; lr:0.000063
epoch:68; metric:emoval; train:0.9315; eval:0.5630; lr:0.000063
epoch:69; metric:emoval; train:0.9297; eval:0.5673; lr:0.000063
epoch:70; metric:emoval; train:0.9321; eval:0.5627; lr:0.000063
epoch:71; metric:emoval; train:0.9318; eval:0.5717; lr:0.000063
epoch:72; metric:emoval; train:0.9308; eval:0.5658; lr:0.000063
epoch:73; metric:emoval; train:0.9362; eval:0.5673; lr:0.000063
Early stopping at epoch 73, best epoch: 43
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 42, duration: 201.707768201828 >>>>>
====== Prediction and Saving =======
save results in /root/autodl-tmp/MERTools-master/MERBench/attention_robust_v2/outputs/results-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v2+utt+None_f1:0.7454_acc:0.7480_val:0.6095_1769766376.6387498.npz
save results in /root/autodl-tmp/MERTools-master/MERBench/attention_robust_v2/outputs/results-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v2+utt+None_f1:0.8120_acc:0.8127_val:0.6640_1769766376.6387498.npz
save results in /root/autodl-tmp/MERTools-master/MERBench/attention_robust_v2/outputs/results-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v2+utt+None_f1:0.7470_acc:0.7500_val:0.6436_1769766376.6387498.npz
save results in /root/autodl-tmp/MERTools-master/MERBench/attention_robust_v2/outputs/results-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v2+utt+None_f1:0.8910_acc:0.8933_val:80.0570_1769766376.6387498.npz
